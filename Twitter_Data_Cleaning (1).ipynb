{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e40c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text\n",
      "0    its back   join us live from los angeles for  ...\n",
      "1                                             tomorrow\n",
      "2    want to get into some legendary action    shop...\n",
      "3    the freetoplay fastpaced arena shooter youve b...\n",
      "4    from ui to controls and visuals see what our t...\n",
      "..                                                 ...\n",
      "807                                                   \n",
      "808                                            so true\n",
      "809             whats your favorite epic gamer t shirt\n",
      "810  welcome to the jungle play  new season wild on...\n",
      "811  play as a child climbing a clock tower in sear...\n",
      "\n",
      "[812 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('NodeXL_tweets_data_test.csv')\n",
    "\n",
    "# Function to clean tweet text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Check if the entry is a string\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'www\\S+', '', text)   # Remove URLs\n",
    "        text = re.sub(r'@\\w+', '', text)     # Remove @mentions\n",
    "        text = re.sub(r'#\\w+', '', text)     # Remove hashtags\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters and punctuation\n",
    "        text = re.sub(r'\\d+', '', text)      # Remove digits\n",
    "        # Remove special characters representing dates and times\n",
    "        text = re.sub(r'\\b(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\b\\s+\\d{1,2},\\s+\\d{4}\\s+â€¢\\s+\\d{1,2}:\\d{2}\\s+(?:am|pm)\\s+utc', '', text)\n",
    "        # Normalize text to remove remaining special Unicode characters\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "        return text.strip()\n",
    "    else:\n",
    "        return ''  # Return an empty string for non-string entries\n",
    "\n",
    "# Apply the clean_text function to the 'Text' column and overwrite it\n",
    "data['Text'] = data['Text'].apply(clean_text)\n",
    "\n",
    "# Export the cleaned data to a new CSV with a different name\n",
    "data.to_csv('cleaned_ubisoft_twitter_data_test1.csv', index=False)\n",
    "\n",
    "# Display the cleaned data (optional)\n",
    "print(data[['Text']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50084877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
